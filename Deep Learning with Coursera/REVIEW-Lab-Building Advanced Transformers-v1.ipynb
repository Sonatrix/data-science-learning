{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- Understand the core components of a Transformer architecture.\n",
    "- Implement a multi-head self-attention mechanism from scratch.\n",
    "- Train and evaluate a Transformer for time series prediction.\n",
    "- Handle preprocessing and scaling for time series data effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Transformer?\n",
    "\n",
    "The Transformer architecture was introduced in the paper *\"Attention Is All You Need\"*. It revolutionized natural language processing by using attention mechanisms instead of recurrence.\n",
    "\n",
    "### Key Components:\n",
    "- **Input Embedding:** Converts input tokens (or time steps) into vectors.\n",
    "- **Positional Encoding:** Injects information about the position of input tokens.\n",
    "- **Multi-Head Self-Attention:** Allows the model to focus on different parts of the input sequence.\n",
    "- **Feedforward Layers:** Process the attended information.\n",
    "- **Layer Normalization & Residual Connections:** Stabilize and speed up training.\n",
    "\n",
    "> Transformers are now widely used not only in NLP but also in time series forecasting, image recognition, and more.\n",
    "\n",
    "**Next:** You will implement parts of this architecture step-by-step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/pkverma/miniconda3/lib/python3.12/site-packages (2.19.0)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (76.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/pkverma/miniconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /home/pkverma/miniconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in /home/pkverma/miniconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-20.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /home/pkverma/miniconda3/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/pkverma/.local/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /home/pkverma/miniconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /home/pkverma/miniconda3/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /home/pkverma/miniconda3/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from requests) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 00:19:51.087200: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-16 00:19:51.843370: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747354792.121466    2941 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747354792.180853    2941 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747354792.542118    2941 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747354792.542191    2941 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747354792.542193    2941 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747354792.542194    2941 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-16 00:19:52.605768: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       100.993428\n",
       "1        99.773496\n",
       "2       101.395427\n",
       "3       103.196135\n",
       "4        99.731793\n",
       "           ...    \n",
       "1995    201.940200\n",
       "1996    199.796882\n",
       "1997    198.136201\n",
       "1998    199.623841\n",
       "1999    198.510195\n",
       "Name: Close, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 00:31:54.022942: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 353ms/step - loss: 16.9136\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 341ms/step - loss: 0.2006\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 345ms/step - loss: 0.1678\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 350ms/step - loss: 0.1836\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 334ms/step - loss: 0.1430\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 343ms/step - loss: 0.1099\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 346ms/step - loss: 0.1731\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 292ms/step - loss: 0.1017\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 336ms/step - loss: 0.1793\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 343ms/step - loss: 0.1678\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 345ms/step - loss: 0.1402\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 329ms/step - loss: 0.1016\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 344ms/step - loss: 0.1094\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 313ms/step - loss: 0.1021\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 328ms/step - loss: 0.0810\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 345ms/step - loss: 0.0627\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 329ms/step - loss: 0.0594\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 339ms/step - loss: 0.0854\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 344ms/step - loss: 0.0683\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 320ms/step - loss: 0.0522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f022c1a6570>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 132ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    "\n",
    "# Prepare true values for comparison\n",
    "true_values = scaler.inverse_transform(data.reshape(-1, 1))\n",
    "\n",
    "# Plot the predictions vs true values\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(true_values, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.title('Predictions vs True Data (Both Scaled Back)')\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 165ms/step - loss: 8.1807\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 255ms/step - loss: 1.3482\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - loss: 0.8726\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 228ms/step - loss: 0.4298\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 248ms/step - loss: 0.1864\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 235ms/step - loss: 0.1442\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 241ms/step - loss: 0.0800\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 240ms/step - loss: 0.0570\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 247ms/step - loss: 0.0488\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 240ms/step - loss: 0.0429\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 248ms/step - loss: 0.0333\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 249ms/step - loss: 0.0339\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 244ms/step - loss: 0.0279\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 242ms/step - loss: 0.0289\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 248ms/step - loss: 0.0263\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 254ms/step - loss: 0.0251\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 246ms/step - loss: 0.0201\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 244ms/step - loss: 0.0230\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 245ms/step - loss: 0.0189\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 249ms/step - loss: 0.0248\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - loss: 0.0017\n",
      "Test loss: 0.0016079959459602833\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 120ms/step - loss: 0.0229\n",
      "Epoch 2/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 163ms/step - loss: 0.0248\n",
      "Epoch 3/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 163ms/step - loss: 0.0355\n",
      "Epoch 4/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 208ms/step - loss: 0.0225\n",
      "Epoch 5/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 202ms/step - loss: 0.0164\n",
      "Epoch 6/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 0.0186\n",
      "Epoch 7/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 152ms/step - loss: 0.0151\n",
      "Epoch 8/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 153ms/step - loss: 0.0182\n",
      "Epoch 9/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 154ms/step - loss: 0.0234\n",
      "Epoch 10/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 169ms/step - loss: 0.0165\n",
      "Epoch 11/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 159ms/step - loss: 0.0161\n",
      "Epoch 12/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 155ms/step - loss: 0.0335\n",
      "Epoch 13/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 153ms/step - loss: 0.0322\n",
      "Epoch 14/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 187ms/step - loss: 0.0161\n",
      "Epoch 15/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 267ms/step - loss: 0.0143\n",
      "Epoch 16/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 169ms/step - loss: 0.0173\n",
      "Epoch 17/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 174ms/step - loss: 0.0159\n",
      "Epoch 18/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 159ms/step - loss: 0.0110\n",
      "Epoch 19/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 176ms/step - loss: 0.0129\n",
      "Epoch 20/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 183ms/step - loss: 0.0187\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 0.0033    \n",
      "Test loss with batch size 16: 0.004707826301455498\n",
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 382ms/step - loss: 0.0128\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 417ms/step - loss: 0.0062\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 398ms/step - loss: 0.0041\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 391ms/step - loss: 0.0033\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 421ms/step - loss: 0.0030\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 388ms/step - loss: 0.0030\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 390ms/step - loss: 0.0031\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 392ms/step - loss: 0.0028\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 410ms/step - loss: 0.0029\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 413ms/step - loss: 0.0030\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 410ms/step - loss: 0.0036\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 459ms/step - loss: 0.0032\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 409ms/step - loss: 0.0034\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 389ms/step - loss: 0.0032\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 417ms/step - loss: 0.0026\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 417ms/step - loss: 0.0026\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 428ms/step - loss: 0.0026\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 428ms/step - loss: 0.0027\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 415ms/step - loss: 0.0032\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 412ms/step - loss: 0.0034\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 0.0010\n",
      "Test loss with batch size 64: 0.0006698707002215087\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - loss: 0.2728\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 230ms/step - loss: 0.2963\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 228ms/step - loss: 0.2968\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 239ms/step - loss: 0.2914\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 324ms/step - loss: 0.2914\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 341ms/step - loss: 0.2982\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 311ms/step - loss: 0.2955\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 319ms/step - loss: 0.2913\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 319ms/step - loss: 0.2952\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 312ms/step - loss: 0.2957\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 319ms/step - loss: 0.2951\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 316ms/step - loss: 0.2893\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 309ms/step - loss: 0.3084\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 315ms/step - loss: 0.6033\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 352ms/step - loss: 2.3640\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 322ms/step - loss: 2.3637\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 315ms/step - loss: 2.3639\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 316ms/step - loss: 2.3476\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 318ms/step - loss: 2.3770\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 319ms/step - loss: 2.3781\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - loss: 1.7508\n",
      "Test loss with tanh activation: 2.3743340969085693\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "prev_pub_hash": "8aae4de69f29de06e63c5f2d04ef24811d42d1553c8ac316f7ad75d55f2c2d79"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
