{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KEYrzG2vB8Ip"
   },
   "outputs": [],
   "source": [
    "!!pip install litellm\n",
    "\n",
    "# Important!!!\n",
    "#\n",
    "# <---- Set your 'OPENAI_API_KEY' as a secret over there with the \"key\" icon\n",
    "#\n",
    "#\n",
    "import os\n",
    "#api_base = f\"http://0.0.0.0:4000\" # base url for server\n",
    "api_base=f\"http://localhost:11434\"\n",
    "#openai.api_base = api_base\n",
    "#openai.api_key = \"temp-key\"\n",
    "#(openai.api_base)\n",
    "#from google.colab import userdata\n",
    "#api_key = userdata.get('OPENAI_API_KEY')\n",
    "#os.environ['OPENAI_API_KEY'] = openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mwe2eeOQB0cC",
    "outputId": "8ad29cf6-8e41-4172-9c5f-47c68ddbaa2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants a function to swap the keys and values in a dictionary. Let me think about how to approach this.\n",
      "\n",
      "First, I remember that in Python, dictionaries can't have duplicate keys, but when swapping, the values might not be hashable. For example, if the original values are lists or other mutable types, swapping them would cause issues. But the user didn't mention handling such cases, so maybe I should assume that all values are hashable and can be used as keys.\n",
      "\n",
      "So the basic idea is to create a new dictionary where each key-value pair is reversed. For example, if the original is {a: b, c: d}, the swapped would be {b: a, d: c}.\n",
      "\n",
      "But wait, if there are duplicate values in the original dictionary, swapping would result in the last occurrence of a value becoming the key. Because when you loop through the items, later entries would overwrite earlier ones. So the function should handle that.\n",
      "\n",
      "How to implement this in Python? Let's think. The function would take a dictionary as input and return a new dictionary.\n",
      "\n",
      "One way is to iterate over the items of the original dictionary. For each key-value pair, we add the value as a key and the original key as the value. But if the value is already a key in the new dictionary, it will be overwritten. So the order of iteration matters here.\n",
      "\n",
      "But the user might not care about preserving the order, but in Python 3.7+, dictionaries maintain insertion order. However, the problem statement doesn't specify any particular order requirements. So the function can proceed as is.\n",
      "\n",
      "So the code would be something like:\n",
      "\n",
      "def swap_dict(d):\n",
      "    return {v: k for k, v in d.items()}\n",
      "\n",
      "Wait, but what if the original dictionary has values that are not hashable? Like a list. Then this code would throw a TypeError. But the user didn't mention handling that. So maybe the function is intended for dictionaries with hashable values.\n",
      "\n",
      "But the user said \"write a function to swap the keys and values in a dictionary.\" So perhaps the function is supposed to handle that, but maybe the user is expecting a basic implementation.\n",
      "\n",
      "Another thing: if the original dictionary has multiple entries with the same value, the last one will be the one that's kept. For example, if the original is {1: 'a', 2: 'a'}, then the swapped would be {'a': 2}.\n",
      "\n",
      "So the code above would handle that.\n",
      "\n",
      "But what about if the original dictionary has values that are not hashable? Like a list. Then the code would raise an error. But the user didn't mention that, so maybe the function is intended for cases where the values are hashable.\n",
      "\n",
      "So the function is as simple as that. But wait, in Python, the keys of a dictionary must be hashable. So when swapping, the original values must be hashable. So the function is correct as long as the input dictionary's values are hashable.\n",
      "\n",
      "So the code is straightforward. Let me test with an example.\n",
      "\n",
      "Test case 1: original is {1: 'a', 2: 'b'}, swapped should be {'a':1, 'b':2}.\n",
      "\n",
      "Test case 2: original is {1: 2, 3: 4}, swapped is {2:1, 4:3}.\n",
      "\n",
      "Another test case: original is {1: 'a', 2: 'a'}, swapped is {'a':2}.\n",
      "\n",
      "Yes, that's correct.\n",
      "\n",
      "So the function is as simple as the dictionary comprehension. But maybe the user wants to handle the case where the values are not hashable? But the question doesn't mention that. So the answer is the code as above.\n",
      "\n",
      "But wait, the user said \"you are an expert software engineer that prefers functional programming.\" So maybe the function should be written in a functional style. But in Python, the code is already functional. Using a dictionary comprehension is a functional approach.\n",
      "\n",
      "So the answer is the function that returns {v: k for k, v in d.items()}.\n",
      "\n",
      "But wait, what if the original dictionary has values that are not hashable? Then the code would throw an error. But the user didn't mention handling that. So the function is correct as per the given problem.\n",
      "\n",
      "So the final answer is the function as written.\n",
      "</think>\n",
      "\n",
      "```python\n",
      "def swap_dict(d):\n",
      "    \"\"\"\n",
      "    Swap the keys and values in a dictionary.\n",
      "    \n",
      "    Parameters:\n",
      "    d (dict): A dictionary with hashable values.\n",
      "    \n",
      "    Returns:\n",
      "    dict: A new dictionary where the keys and values are swapped.\n",
      "    \n",
      "    Note:\n",
      "    - This function assumes that all values in the input dictionary are hashable.\n",
      "    - If the original dictionary contains duplicate values, the last occurrence will be preserved in the swapped dictionary.\n",
      "    \"\"\"\n",
      "    return {v: k for k, v in d.items()}\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "- The function uses a dictionary comprehension to create a new dictionary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m01:09:21 - LiteLLM:ERROR\u001b[0m: litellm_logging.py:3420 - Error creating standard logging object - __annotations__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pkverma/miniconda3/lib/python3.12/site-packages/litellm/litellm_core_utils/litellm_logging.py\", line 3402, in get_standard_logging_object_payload\n",
      "    model_parameters=ModelParamHelper.get_standard_logging_model_parameters(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/pkverma/miniconda3/lib/python3.12/site-packages/litellm/litellm_core_utils/model_param_helper.py\", line 28, in get_standard_logging_model_parameters\n",
      "    ModelParamHelper._get_relevant_args_to_use_for_logging()\n",
      "  File \"/home/pkverma/miniconda3/lib/python3.12/site-packages/litellm/litellm_core_utils/model_param_helper.py\", line 45, in _get_relevant_args_to_use_for_logging\n",
      "    all_openai_llm_api_params = ModelParamHelper._get_all_llm_api_params()\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/pkverma/miniconda3/lib/python3.12/site-packages/litellm/litellm_core_utils/model_param_helper.py\", line 65, in _get_all_llm_api_params\n",
      "    ModelParamHelper._get_litellm_supported_transcription_kwargs()\n",
      "  File \"/home/pkverma/miniconda3/lib/python3.12/site-packages/litellm/litellm_core_utils/model_param_helper.py\", line 126, in _get_litellm_supported_transcription_kwargs\n",
      "    return set(TranscriptionCreateParams.__annotations__.keys())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/pkverma/miniconda3/lib/python3.12/typing.py\", line 1167, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: __annotations__\n",
      "\u001b[92m01:09:21 - LiteLLM:ERROR\u001b[0m: litellm_logging.py:3420 - Error creating standard logging object - __annotations__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pkverma/miniconda3/lib/python3.12/site-packages/litellm/litellm_core_utils/litellm_logging.py\", line 3402, in get_standard_logging_object_payload\n",
      "    model_parameters=ModelParamHelper.get_standard_logging_model_parameters(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/pkverma/miniconda3/lib/python3.12/site-packages/litellm/litellm_core_utils/model_param_helper.py\", line 28, in get_standard_logging_model_parameters\n",
      "    ModelParamHelper._get_relevant_args_to_use_for_logging()\n",
      "  File \"/home/pkverma/miniconda3/lib/python3.12/site-packages/litellm/litellm_core_utils/model_param_helper.py\", line 45, in _get_relevant_args_to_use_for_logging\n",
      "    all_openai_llm_api_params = ModelParamHelper._get_all_llm_api_params()\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/pkverma/miniconda3/lib/python3.12/site-packages/litellm/litellm_core_utils/model_param_helper.py\", line 65, in _get_all_llm_api_params\n",
      "    ModelParamHelper._get_litellm_supported_transcription_kwargs()\n",
      "  File \"/home/pkverma/miniconda3/lib/python3.12/site-packages/litellm/litellm_core_utils/model_param_helper.py\", line 126, in _get_litellm_supported_transcription_kwargs\n",
      "    return set(TranscriptionCreateParams.__annotations__.keys())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/pkverma/miniconda3/lib/python3.12/typing.py\", line 1167, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: __annotations__\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "def generate_response(messages: List[Dict]) -> str:\n",
    "    \"\"\"Call LLM to get response\"\"\"\n",
    "    response = completion(\n",
    "        model=\"ollama/qwen3:4b\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024,\n",
    "        api_base=\"http://localhost:11434\"\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert software engineer that prefers functional programming.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a function to swap the keys and values in a dictionary.\"}\n",
    "]\n",
    "\n",
    "response = generate_response(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
