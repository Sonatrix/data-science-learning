{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a150c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/pkverma/miniconda3/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/pkverma/miniconda3/lib/python3.12/site-packages (from torch) (78.1.1)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/pkverma/miniconda3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Installing collected packages: sympy\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "vllm 0.7.3 requires numpy<2.0.0, but you have numpy 2.2.6 which is incompatible.\n",
      "vllm 0.7.3 requires transformers>=4.48.2, but you have transformers 4.42.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed sympy-1.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b995c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Task 1: Load and preprocess League of Legends data\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Import required libraries\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/__init__.py:46\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     47\u001b[39m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[32m     48\u001b[39m     ArrowDtype,\n\u001b[32m     49\u001b[39m     Int8Dtype,\n\u001b[32m     50\u001b[39m     Int16Dtype,\n\u001b[32m     51\u001b[39m     Int32Dtype,\n\u001b[32m     52\u001b[39m     Int64Dtype,\n\u001b[32m     53\u001b[39m     UInt8Dtype,\n\u001b[32m     54\u001b[39m     UInt16Dtype,\n\u001b[32m     55\u001b[39m     UInt32Dtype,\n\u001b[32m     56\u001b[39m     UInt64Dtype,\n\u001b[32m     57\u001b[39m     Float32Dtype,\n\u001b[32m     58\u001b[39m     Float64Dtype,\n\u001b[32m     59\u001b[39m     CategoricalDtype,\n\u001b[32m     60\u001b[39m     PeriodDtype,\n\u001b[32m     61\u001b[39m     IntervalDtype,\n\u001b[32m     62\u001b[39m     DatetimeTZDtype,\n\u001b[32m     63\u001b[39m     StringDtype,\n\u001b[32m     64\u001b[39m     BooleanDtype,\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[32m     66\u001b[39m     NA,\n\u001b[32m     67\u001b[39m     isna,\n\u001b[32m     68\u001b[39m     isnull,\n\u001b[32m     69\u001b[39m     notna,\n\u001b[32m     70\u001b[39m     notnull,\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[32m     72\u001b[39m     Index,\n\u001b[32m     73\u001b[39m     CategoricalIndex,\n\u001b[32m     74\u001b[39m     RangeIndex,\n\u001b[32m     75\u001b[39m     MultiIndex,\n\u001b[32m     76\u001b[39m     IntervalIndex,\n\u001b[32m     77\u001b[39m     TimedeltaIndex,\n\u001b[32m     78\u001b[39m     DatetimeIndex,\n\u001b[32m     79\u001b[39m     PeriodIndex,\n\u001b[32m     80\u001b[39m     IndexSlice,\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[32m     82\u001b[39m     NaT,\n\u001b[32m     83\u001b[39m     Period,\n\u001b[32m     84\u001b[39m     period_range,\n\u001b[32m     85\u001b[39m     Timedelta,\n\u001b[32m     86\u001b[39m     timedelta_range,\n\u001b[32m     87\u001b[39m     Timestamp,\n\u001b[32m     88\u001b[39m     date_range,\n\u001b[32m     89\u001b[39m     bdate_range,\n\u001b[32m     90\u001b[39m     Interval,\n\u001b[32m     91\u001b[39m     interval_range,\n\u001b[32m     92\u001b[39m     DateOffset,\n\u001b[32m     93\u001b[39m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[32m     94\u001b[39m     to_numeric,\n\u001b[32m     95\u001b[39m     to_datetime,\n\u001b[32m     96\u001b[39m     to_timedelta,\n\u001b[32m     97\u001b[39m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[32m     98\u001b[39m     Flags,\n\u001b[32m     99\u001b[39m     Grouper,\n\u001b[32m    100\u001b[39m     factorize,\n\u001b[32m    101\u001b[39m     unique,\n\u001b[32m    102\u001b[39m     value_counts,\n\u001b[32m    103\u001b[39m     NamedAgg,\n\u001b[32m    104\u001b[39m     array,\n\u001b[32m    105\u001b[39m     Categorical,\n\u001b[32m    106\u001b[39m     set_eng_float_format,\n\u001b[32m    107\u001b[39m     Series,\n\u001b[32m    108\u001b[39m     DataFrame,\n\u001b[32m    109\u001b[39m )\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/core/api.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     NaT,\n\u001b[32m      3\u001b[39m     Period,\n\u001b[32m      4\u001b[39m     Timedelta,\n\u001b[32m      5\u001b[39m     Timestamp,\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     ArrowDtype,\n\u001b[32m     11\u001b[39m     CategoricalDtype,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     PeriodDtype,\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/_libs/__init__.py:18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401,E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtslibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     NaT,\n\u001b[32m     21\u001b[39m     NaTType,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     iNaT,\n\u001b[32m     27\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32minterval.pyx:1\u001b[39m, in \u001b[36minit pandas._libs.interval\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# Task 1: Load and preprocess League of Legends data\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "file_path = os.path.expanduser('./league_of_legends_data_large.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Confirm the column names to ensure the target column exists\n",
    "print(\"Columns:\", df.columns)\n",
    "\n",
    "# Replace 'blueWins' with the correct column name if different\n",
    "target_column = 'blueWins'\n",
    "\n",
    "# Ensure the target column exists\n",
    "if target_column not in df.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found in dataset. Please update the code with the correct column name.\")\n",
    "\n",
    "# Split into features and target\n",
    "X = df.drop(columns=target_column)\n",
    "y = df[target_column]\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Check final shapes\n",
    "print(\"X_train_tensor shape:\", X_train_tensor.shape)\n",
    "print(\"y_train_tensor shape:\", y_train_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb1a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_path = os.path.expanduser('~/Downloads/league_of_legends_data_large.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Show all column names\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7876d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Load and preprocess the League of Legends dataset\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "# Load dataset\n",
    "file_path = os.path.expanduser('~/Downloads/league_of_legends_data_large.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define target column correctly\n",
    "target_column = 'win'\n",
    "\n",
    "# Split into features and target\n",
    "X = df.drop(columns=target_column)\n",
    "y = df[target_column]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "print(\"✅ Data loaded and preprocessed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc130466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Define logistic regression model using PyTorch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the logistic regression model class\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "# Set input dimension (number of features)\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegressionModel(input_dim)\n",
    "\n",
    "# Define the loss function (Binary Cross-Entropy Loss)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Define the optimizer (SGD with learning rate 0.01)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "print(\"✅ Logistic Regression model, loss function, and optimizer initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e53fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Model Training\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 1000\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = loss_fn(outputs, y_train_tensor)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Model evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_preds = model(X_train_tensor).squeeze()\n",
    "    test_preds = model(X_test_tensor).squeeze()\n",
    "\n",
    "    train_preds_class = (train_preds >= 0.5).float()\n",
    "    test_preds_class = (test_preds >= 0.5).float()\n",
    "\n",
    "    train_accuracy = (train_preds_class == y_train_tensor).sum().item() / y_train_tensor.size(0)\n",
    "    test_accuracy = (test_preds_class == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "\n",
    "print(f\"\\n✅ Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"✅ Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87216853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialize the model\n",
    "model_l2 = LogisticRegressionModel(input_dim)\n",
    "# Set up the optimizer with L2 regularization\n",
    "optimizer_l2 = optim.SGD(model_l2.parameters(), lr=0.01, weight_decay=0.01)\n",
    "loss_fn_l2 = nn.BCELoss()\n",
    "\n",
    "# Train the model with L2 regularization\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model_l2.train()\n",
    "    optimizer_l2.zero_grad()\n",
    "\n",
    "    outputs = model_l2(X_train_tensor)\n",
    "    loss = loss_fn_l2(outputs, y_train_tensor)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer_l2.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"[L2] Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate the L2-regularized model\n",
    "model_l2.eval()\n",
    "with torch.no_grad():\n",
    "    train_preds_l2 = model_l2(X_train_tensor).squeeze()\n",
    "    test_preds_l2 = model_l2(X_test_tensor).squeeze()\n",
    "\n",
    "    train_preds_class_l2 = (train_preds_l2 >= 0.5).float()\n",
    "    test_preds_class_l2 = (test_preds_l2 >= 0.5).float()\n",
    "\n",
    "    train_accuracy_l2 = (train_preds_class_l2 == y_train_tensor).sum().item() / y_train_tensor.size(0)\n",
    "    test_accuracy_l2 = (test_preds_class_l2 == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "\n",
    "print(f\"\\n✅ L2-Regularized Training Accuracy: {train_accuracy_l2:.4f}\")\n",
    "print(f\"✅ L2-Regularized Test Accuracy: {test_accuracy_l2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_curve, auc\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "model_l2.eval()\n",
    "\n",
    "# Get predicted probabilities\n",
    "with torch.no_grad():\n",
    "    y_test_probs = model_l2(X_test_tensor).squeeze()\n",
    "    y_test_pred = (y_test_probs >= 0.5).float()\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "cm = confusion_matrix(y_test_tensor.numpy(), y_test_pred.numpy())\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Classification Report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test_tensor.numpy(), y_test_pred.numpy(), digits=4))\n",
    "\n",
    "# 3. ROC Curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test_tensor.numpy(), y_test_probs.numpy())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea45fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model (state dict only)\n",
    "torch.save(model_l2.state_dict(), \"logistic_model_l2.pth\")\n",
    "\n",
    "# Re-instantiate a new model with the same architecture\n",
    "loaded_model = LogisticRegressionModel(input_dim)\n",
    "loaded_model.load_state_dict(torch.load(\"logistic_model_l2.pth\"))\n",
    "loaded_model.eval()\n",
    "\n",
    "# Evaluate the loaded model on test data\n",
    "with torch.no_grad():\n",
    "    loaded_outputs = loaded_model(X_test_tensor).squeeze()\n",
    "    loaded_predictions = (loaded_outputs >= 0.5).float()\n",
    "\n",
    "# Calculate and print accuracy\n",
    "loaded_accuracy = (loaded_predictions == y_test_tensor).float().mean()\n",
    "print(f\"Accuracy of loaded model on test set: {loaded_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6689c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.05, 0.1]\n",
    "num_epochs = 100\n",
    "best_accuracy = 0\n",
    "best_lr = None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTraining with learning rate: {lr}\")\n",
    "\n",
    "    # Reinitialize model and optimizer for each learning rate\n",
    "    model = LogisticRegressionModel(input_dim)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor).squeeze()\n",
    "        loss = criterion(outputs, y_train_tensor.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor).squeeze()\n",
    "        predictions = (outputs >= 0.5).float()\n",
    "        accuracy = (predictions == y_test_tensor).float().mean().item()\n",
    "\n",
    "    print(f\"Test accuracy for learning rate {lr}: {accuracy:.4f}\")\n",
    "\n",
    "    # Track best\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_lr = lr\n",
    "\n",
    "print(f\"\\n✅ Best learning rate: {best_lr} with accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be48acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Extract weights from the trained logistic regression model\n",
    "weights = model.linear.weight.data.numpy().flatten()\n",
    "\n",
    "# Step 2: Create DataFrame with feature names and their weights\n",
    "feature_names = X_train.columns  # Assuming you have access to column names here\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': weights\n",
    "})\n",
    "\n",
    "# Step 3: Sort features by absolute importance\n",
    "importance_df['AbsImportance'] = importance_df['Importance'].abs()\n",
    "importance_df = importance_df.sort_values(by='AbsImportance', ascending=False)\n",
    "\n",
    "# Step 4: Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Weight (Importance)')\n",
    "plt.title('Feature Importance from Logistic Regression Model')\n",
    "plt.gca().invert_yaxis()  # Most important on top\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455921c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
